{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display, Javascript\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "# Primeiro, defina a função take_photo() se não estiver definida\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "    js = Javascript('''\n",
        "        async function takePhoto(quality) {\n",
        "            const div = document.createElement('div');\n",
        "            const capture = document.createElement('button');\n",
        "            capture.textContent = 'Capture';\n",
        "            div.appendChild(capture);\n",
        "\n",
        "            const video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "            document.body.appendChild(div);\n",
        "            div.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            // Resize the output to fit the video element.\n",
        "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "            // Wait for Capture to be clicked.\n",
        "            await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            div.remove();\n",
        "            return canvas.toDataURL('image/jpeg', quality);\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "\n",
        "    # Get photo data\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    # Decode Base64 data\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    # Save image\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(binary)\n",
        "    return filename"
      ],
      "metadata": {
        "id": "oLheg77L2ZHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Chama a função para tirar a foto\n",
        "    filename = take_photo()\n",
        "    print('Foto salva como {}'.format(filename))\n",
        "\n",
        "    # Carregar a imagem\n",
        "    img = cv2.imread(filename)\n",
        "\n",
        "    if img is None:\n",
        "        print(\"Erro: Não foi possível carregar a imagem capturada.\")\n",
        "        faces = []\n",
        "        num_pessoas = 0\n",
        "    else:\n",
        "        img_com_deteccao = img.copy()\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "        if face_cascade.empty():\n",
        "            print(\"Erro: Não foi possível carregar o classificador Haar Cascade.\")\n",
        "            faces = []\n",
        "            num_pessoas = 0\n",
        "        else:\n",
        "            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "            num_pessoas = len(faces)\n",
        "            print(f\"Número de rostos detectados: {num_pessoas}\")\n",
        "\n",
        "            # Perguntar os nomes das pessoas detectadas\n",
        "            nomes = []\n",
        "            if num_pessoas > 0:\n",
        "                print(\"=== DIGITE OS NOMES DAS PESSOAS === \\n\")\n",
        "                for i in range(num_pessoas):\n",
        "                    nome = input(f\"Digite o nome da pessoa {i+1}: \")\n",
        "                    nomes.append(nome)\n",
        "                print(\"Nomes registrados com sucesso!\\n\")\n",
        "            else:\n",
        "                print(\"Nenhuma pessoa detectada na foto.\")\n",
        "\n",
        "            # Desenhar retângulos, números e nomes na imagem\n",
        "            for i, (x, y, w, h) in enumerate(faces):\n",
        "                # Desenha o retângulo verde\n",
        "                cv2.rectangle(img_com_deteccao, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "\n",
        "                # Adiciona o número da pessoa\n",
        "                cv2.putText(img_com_deteccao, f\"{i+1}\", (x, y - 10),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "                # Adiciona o nome da pessoa (se disponível)\n",
        "                if i < len(nomes) and nomes[i]:\n",
        "                    # Calcula posição para o nome (abaixo do rosto)\n",
        "                    nome_y = y + h + 25\n",
        "\n",
        "                    # Desenha fundo semi-transparente para o nome\n",
        "                    overlay = img_com_deteccao.copy()\n",
        "                    text_size = cv2.getTextSize(nomes[i], cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]\n",
        "                    cv2.rectangle(overlay, (x, nome_y - 20), (x + text_size[0] + 10, nome_y), (0, 0, 0), -1)\n",
        "                    cv2.addWeighted(overlay, 0.6, img_com_deteccao, 0.4, 0, img_com_deteccao)\n",
        "\n",
        "                    # Adiciona o nome\n",
        "                    cv2.putText(img_com_deteccao, nomes[i], (x + 5, nome_y - 5),\n",
        "                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "            # Exibir resultado\n",
        "            img_com_deteccao_rgb = cv2.cvtColor(img_com_deteccao, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            plt.figure(figsize=(12, 10))\n",
        "            plt.imshow(img_com_deteccao_rgb)\n",
        "\n",
        "            if num_pessoas > 0:\n",
        "                plt.title(f\"Pessoas Detectadas: {num_pessoas}\\nNomes: {', '.join(nomes)}\", fontsize=14)\n",
        "            else:\n",
        "                plt.title(\"Nenhuma pessoa detectada na foto\", fontsize=14)\n",
        "\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "            # Salvar imagem com os nomes\n",
        "            if num_pessoas > 0:\n",
        "                nome_arquivo_saida = 'foto_com_nomes.jpg'\n",
        "                cv2.imwrite(nome_arquivo_saida, img_com_deteccao)\n",
        "                print(f\"Imagem com nomes salva como: {nome_arquivo_saida}\")\n",
        "\n",
        "            # Resumo final\n",
        "            print(\"\\n=== RESUMO DA DETECÇÃO ===\")\n",
        "            print(f\"Total de pessoas detectadas: {num_pessoas}\")\n",
        "            if num_pessoas > 0:\n",
        "                for i, nome in enumerate(nomes, 1):\n",
        "                    print(f\"Pessoa {i}: {nome}\")\n",
        "\n",
        "except Exception as err:\n",
        "    print(f\"Ocorreu um erro: {str(err)}\")\n",
        "    faces = []\n",
        "    num_pessoas = 0\n",
        "    filename = None"
      ],
      "metadata": {
        "id": "7rlHfNcR321z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}